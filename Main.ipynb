{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee89b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import ollama\n",
    "import uuid\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from typing import Dict, List, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145de3f",
   "metadata": {},
   "source": [
    "## ***GLOBAL CONFIGURATIONS***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "564e26b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 21:43:33,094 - httpx - INFO - HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    # Core parameters\n",
    "    INPUT_FILE = \"/mnt/Main Drive/Codes/LLM Agents/Assistant/Facets recognition/Facets Assignment.csv\"\n",
    "    COLLECTION_NAME = \"conversation_facets\"\n",
    "    EMBEDDING_MODEL = \"nomic-embed-text-v1.5\"\n",
    "    \n",
    "    # Batch processing settings\n",
    "    PREPROCESS_BATCH_SIZE = 10\n",
    "    CATEGORIZE_BATCH_SIZE = 50\n",
    "    SCORING_BATCH_SIZE = 20\n",
    "    \n",
    "    # LLM settings\n",
    "    LLM_MODEL = \"llama3.2\"\n",
    "    LLM_TEMPERATURE = 0.1\n",
    "    \n",
    "    # Paths\n",
    "    METADATA_FILE = \"facet_metadata.json\"\n",
    "    CATEGORY_FILE = \"facet_categories.json\"\n",
    "    RESULTS_FILE = \"evaluation_results.json\"\n",
    "    \n",
    "    # Qdrant settings\n",
    "    QDRANT_HOST = \"localhost\"\n",
    "    QDRANT_PORT = 6333\n",
    "    \n",
    "    # Debugging\n",
    "    DEBUG_MODE = False\n",
    "    VALIDATE_CATEGORIZATION = True\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG if Config.DEBUG_MODE else logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('ConversationEvaluator')\n",
    "\n",
    "# Initialize Qdrant client\n",
    "client = QdrantClient(\n",
    "    host=Config.QDRANT_HOST,\n",
    "    port=Config.QDRANT_PORT\n",
    ")\n",
    "\n",
    "# Initialize Nomic embeddings\n",
    "embed_model = NomicEmbeddings(model=Config.EMBEDDING_MODEL, inference_mode=\"local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d9ed4",
   "metadata": {},
   "source": [
    "## ***VECTOR DATABASE***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec948fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QdrantVectorDB:\n",
    "    def __init__(self, collection_name=Config.COLLECTION_NAME):\n",
    "        self.client = client\n",
    "        self.collection_name = collection_name\n",
    "        self.embed_model = embed_model\n",
    "        self._initialize_collection()\n",
    "    \n",
    "    def _initialize_collection(self):\n",
    "        \"\"\"Create collection if it doesn't exist\"\"\"\n",
    "        try:\n",
    "            self.client.get_collection(self.collection_name)\n",
    "            logger.info(f\"Collection {self.collection_name} already exists\")\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Creating new collection: {self.collection_name}\")\n",
    "            self.client.recreate_collection(\n",
    "                collection_name=self.collection_name,\n",
    "                vectors_config=VectorParams(\n",
    "                    size=768,  # Nomic embedding size\n",
    "                    distance=Distance.COSINE\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def store_facets(self, metadata: Dict):\n",
    "        \"\"\"Store facet metadata in vector database in batches\"\"\"\n",
    "        points = []\n",
    "        for facet_id, data in metadata.items():\n",
    "            # Create payload\n",
    "            payload = {\n",
    "                \"id\": facet_id,\n",
    "                \"original\": data[\"original\"],\n",
    "                \"scoring_guideline\": data[\"scoring_guideline\"],\n",
    "                \"primary_category\": data.get(\"primary_category\", \"\"),\n",
    "                \"subcategory\": data.get(\"subcategory\", \"\")\n",
    "            }\n",
    "            \n",
    "            # Generate embedding\n",
    "            text = f\"{facet_id}: {data['scoring_guideline']}\"\n",
    "            embedding = self.embed_model.embed_query(text)\n",
    "            \n",
    "            points.append(PointStruct(\n",
    "                id=hash(facet_id) % (2**64),\n",
    "                vector=embedding,\n",
    "                payload=payload\n",
    "            ))\n",
    "            \n",
    "            # Store in batches\n",
    "            if len(points) >= Config.PREPROCESS_BATCH_SIZE:\n",
    "                self._upsert_points(points)\n",
    "                points = []\n",
    "        \n",
    "        # Store remaining points\n",
    "        if points:\n",
    "            self._upsert_points(points)\n",
    "    \n",
    "    def _upsert_points(self, points: List):\n",
    "        \"\"\"Store points with error handling\"\"\"\n",
    "        try:\n",
    "            self.client.upsert(\n",
    "                collection_name=self.collection_name,\n",
    "                points=points,\n",
    "                wait=True\n",
    "            )\n",
    "            logger.info(f\"Stored {len(points)} facets in vector database\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to store points: {str(e)}\")\n",
    "    \n",
    "    def retrieve_facet(self, facet_id: str) -> Dict:\n",
    "        \"\"\"Retrieve facet by exact ID match\"\"\"\n",
    "        try:\n",
    "            result = self.client.scroll(\n",
    "                collection_name=self.collection_name,\n",
    "                scroll_filter={\n",
    "                    \"must\": [{\"key\": \"id\", \"match\": {\"value\": facet_id}}]\n",
    "                },\n",
    "                limit=1,\n",
    "                with_payload=True\n",
    "            )\n",
    "            return result[0][0].payload if result[0] else None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Retrieval failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def semantic_search(self, query: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Find similar facets using semantic search\"\"\"\n",
    "        try:\n",
    "            query_embedding = self.embed_model.embed_query(query)\n",
    "            results = self.client.search(\n",
    "                collection_name=self.collection_name,\n",
    "                query_vector=query_embedding,\n",
    "                limit=top_k,\n",
    "                with_payload=True\n",
    "            )\n",
    "            return [{\n",
    "                \"id\": hit.payload[\"id\"],\n",
    "                \"score\": hit.score,\n",
    "                \"payload\": hit.payload\n",
    "            } for hit in results]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Semantic search failed: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def get_all_facets(self) -> Dict:\n",
    "        \"\"\"Retrieve all facets from vector database\"\"\"\n",
    "        try:\n",
    "            results = self.client.scroll(\n",
    "                collection_name=self.collection_name,\n",
    "                limit=10000,\n",
    "                with_payload=True\n",
    "            )\n",
    "            return {hit.payload[\"id\"]: hit.payload for hit in results[0]}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to get all facets: {str(e)}\")\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c7567",
   "metadata": {},
   "source": [
    "## ***PREPROCESSING CLASSES***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0561216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FacetPreprocessor:\n",
    "#     def __init__(self, input_file=Config.INPUT_FILE):\n",
    "#         self.input_file = input_file\n",
    "        \n",
    "#     def load_raw_facets(self) -> Tuple[str, int]:\n",
    "#         \"\"\"Load raw facet data from CSV and return content + facet count\"\"\"\n",
    "#         try:\n",
    "#             with open(self.input_file, 'r') as f:\n",
    "#                 content = f.read()\n",
    "#                 # Count non-empty lines\n",
    "#                 facet_count = sum(1 for line in content.split('\\n') if line.strip())\n",
    "#                 logger.info(f\"Loaded raw CSV with {facet_count} facets\")\n",
    "#                 return content, facet_count\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Failed to load facets: {str(e)}\")\n",
    "#             return \"\", 0\n",
    "\n",
    "#     def preprocess_facets(self) -> Dict:\n",
    "#         \"\"\"Leting the LLM handle entire preprocessing with batch support\"\"\"\n",
    "#         raw_csv, facet_count = self.load_raw_facets()\n",
    "        \n",
    "#         # If file is large, process in batches\n",
    "#         if facet_count > Config.PREPROCESS_BATCH_SIZE:\n",
    "#             logger.info(f\"Processing large CSV in batches of {Config.PREPROCESS_BATCH_SIZE}\")\n",
    "#             return self._batch_preprocess(raw_csv, facet_count)\n",
    "#         else:\n",
    "#             logger.info(\"Processing CSV in single batch\")\n",
    "#             return self._process_batch(raw_csv)\n",
    "\n",
    "#     def _batch_preprocess(self, raw_csv: str, facet_count: int) -> Dict:\n",
    "#         \"\"\"Process CSV in batches\"\"\"\n",
    "#         metadata = {}\n",
    "#         lines = raw_csv.split('\\n')\n",
    "#         batch_count = (facet_count + Config.PREPROCESS_BATCH_SIZE - 1) // Config.PREPROCESS_BATCH_SIZE\n",
    "        \n",
    "#         for i in range(batch_count):\n",
    "#             start = i * Config.PREPROCESS_BATCH_SIZE\n",
    "#             end = min((i + 1) * Config.PREPROCESS_BATCH_SIZE, facet_count)\n",
    "#             batch_lines = lines[start:end]\n",
    "#             batch_csv = \"\\n\".join(batch_lines)\n",
    "            \n",
    "#             logger.info(f\"Processing batch {i+1}/{batch_count} ({len(batch_lines)} facets)\")\n",
    "#             batch_metadata = self._process_batch(batch_csv)\n",
    "#             metadata.update(batch_metadata)\n",
    "        \n",
    "#         return metadata\n",
    "\n",
    "#     def _process_batch(self, batch_csv: str) -> Dict:\n",
    "#         prompt = f\"\"\"\n",
    "#         You are a facet standardization specialist. Perform these tasks with strict rules:\n",
    "\n",
    "#         1. **Input Processing**:\n",
    "#            - Process the raw CSV content containing facets\n",
    "#            - Extract all facet names from the provided content\n",
    "\n",
    "#         2. **Normalization**:\n",
    "#            - Remove all numbering prefixes (e.g., \"644.\" → \"\")\n",
    "#            - Extract core facet names (e.g., \"HEXACO domain: Honesty-Humility\" → \"Honesty-Humility\")\n",
    "#            - Convert to lowercase_with_underscores format (e.g., \"Democratic Leadership\" → \"democratic_leadership\")\n",
    "\n",
    "#         3. **Metadata Generation**:\n",
    "#            - Create 1-sentence scoring guidelines for each facet: \n",
    "#              \"Score 1-5 where 1=[low extreme], 5=[high extreme] based on [criterion]\"\n",
    "#            - Flag facets needing external verification (medical, spiritual, technical)\n",
    "\n",
    "#         4. **Output Constraints**:\n",
    "#            - JSON format ONLY\n",
    "#            - Structure: {{\"facet_name\": {{\"original\": \"...\", \"scoring_guideline\": \"...\", \"needs_external_data\": bool}}}}\n",
    "#            - Include ALL facets from the input\n",
    "\n",
    "#         Raw CSV Content:\n",
    "#         {batch_csv}\n",
    "\n",
    "#         Output JSON format:\n",
    "#         {{\n",
    "#           \"facet_metadata\": {{\n",
    "#             \"normalized_name_1\": {{\n",
    "#               \"original\": \"Original facet text\",\n",
    "#               \"scoring_guideline\": \"Scoring description\",\n",
    "#               \"needs_external_data\": false\n",
    "#             }},\n",
    "#             \"normalized_name_2\": {{\n",
    "#               \"original\": \"Original facet text\",\n",
    "#               \"scoring_guideline\": \"Scoring description\",\n",
    "#               \"needs_external_data\": true\n",
    "#             }}\n",
    "#           }}\n",
    "#         }}\n",
    "#         \"\"\"\n",
    "        \n",
    "        \n",
    "#         response = self.query_llm(prompt)\n",
    "#         try:\n",
    "#             return json.loads(response)['facet_metadata']\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Failed to parse preprocessing response: {str(e)}\")\n",
    "#             return {}\n",
    "\n",
    "#     def query_llm(self, prompt: str) -> str:\n",
    "#         try:\n",
    "#             response = ollama.generate(\n",
    "#                 model=Config.LLM_MODEL,\n",
    "#                 prompt=prompt,\n",
    "#                 format=\"json\",\n",
    "#                 options={\"temperature\": 0.05}\n",
    "#             )\n",
    "#             return response['response'].strip()\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"LLM query failed: {str(e)}\")\n",
    "#             return \"{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca3d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacetPreprocessor:\n",
    "    def __init__(self, input_file=Config.INPUT_FILE):\n",
    "        self.input_file = input_file\n",
    "        self.raw_lines = []\n",
    "        \n",
    "    def load_raw_facets(self) -> List[str]:\n",
    "        \"\"\"Load raw facet data from CSV\"\"\"\n",
    "        try:\n",
    "            with open(self.input_file, 'r') as f:\n",
    "                self.raw_lines = [line.strip() for line in f if line.strip()]\n",
    "            logger.info(f\"Loaded {len(self.raw_lines)} raw facets from CSV\")\n",
    "            return self.raw_lines\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load facets: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def preprocess_facets(self) -> Dict:\n",
    "        \"\"\"Process raw CSV content to generate facet metadata with incremental saving\"\"\"\n",
    "        if not self.raw_lines:\n",
    "            self.load_raw_facets()\n",
    "        \n",
    "        # Load existing metadata if available\n",
    "        metadata = {}\n",
    "        if os.path.exists(Config.METADATA_FILE):\n",
    "            try:\n",
    "                with open(Config.METADATA_FILE, 'r') as f:\n",
    "                    metadata = json.load(f)\n",
    "                logger.info(f\"Loaded existing metadata with {len(metadata)} facets\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to load existing metadata: {str(e)}\")\n",
    "        \n",
    "        batches = [self.raw_lines[i:i + Config.PREPROCESS_BATCH_SIZE] \n",
    "                   for i in range(0, len(self.raw_lines), Config.PREPROCESS_BATCH_SIZE)]\n",
    "        \n",
    "        for i, batch in enumerate(batches):\n",
    "            # Skip already processed batches\n",
    "            batch_csv = \"\\n\".join(batch)\n",
    "            if self._is_batch_processed(metadata, batch):\n",
    "                logger.info(f\"Skipping already processed batch {i+1}/{len(batches)}\")\n",
    "                continue\n",
    "                \n",
    "            logger.info(f\"Processing batch {i+1}/{len(batches)} with {len(batch)} facets\")\n",
    "            batch_metadata = self._process_batch(batch_csv)\n",
    "            \n",
    "            # Update metadata and save incrementally\n",
    "            metadata.update(batch_metadata)\n",
    "            self._save_metadata(metadata)\n",
    "        \n",
    "        logger.info(f\"Preprocessing complete. Total facets: {len(metadata)}\")\n",
    "        return metadata\n",
    "\n",
    "    def _is_batch_processed(self, metadata: Dict, batch: List[str]) -> bool:\n",
    "        \"\"\"Check if batch is already in metadata\"\"\"\n",
    "        for line in batch:\n",
    "            # Check if any line from batch exists in metadata\n",
    "            for facet_data in metadata.values():\n",
    "                if line == facet_data[\"original\"]:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def _process_batch(self, batch_csv: str) -> Dict:\n",
    "        \"\"\"Process a batch of raw CSV content\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are a facet standardization specialist. Your role is to extract the meaning from the input, if the input dosen't look like a category discard it.Perform these tasks with strict rules:\n",
    "\n",
    "        1. **Input Processing**:\n",
    "           - Process the raw CSV content containing facets\n",
    "           - Extract all facet names from the provided content remove the extra text\n",
    "           \n",
    "\n",
    "        2. **Normalization**:\n",
    "           - Remove all numbering prefixes (e.g., \"644.\" → \"\")\n",
    "           - Extract core facet names (e.g., \"HEXACO domain: Honesty-Humility\" → \"Honesty-Humility\", \"Psychomotor Ability Subcomponents:Mysteriousness\" → \"Mysteriousness\",\n",
    "           \"big five facet openness \\u2013 artistic interests\" → \"artistic_interests\")\n",
    "           - Convert to lowercase_with_underscores format (e.g., \"Democratic Leadership\" → \"democratic_leadership\")\n",
    "\n",
    "        3. **Metadata Generation**:\n",
    "           - Create 1-sentence scoring guidelines for each facet: \n",
    "             \"Score 1-5 where 1=[low extreme], 5=[high extreme] based on [criterion]\"\n",
    "\n",
    "        4. **Output Constraints**:\n",
    "           - JSON format ONLY\n",
    "           - Structure: {{\"facet_name\": {{\"original\": str, \"scoring_guideline\": str, \"needs_external_data\": bool}}}}\n",
    "           - Include ALL facets from the input\n",
    "\n",
    "        Raw CSV Content:\n",
    "        {batch_csv}\n",
    "\n",
    "        Output JSON format:\n",
    "        {{\n",
    "          \"facet_metadata\": {{\n",
    "            \"normalized_name_1\": {{\n",
    "              \"original\": \"Original facet text\",\n",
    "              \"scoring_guideline\": \"Scoring description\",\n",
    "            }},\n",
    "            \"normalized_name_2\": {{\n",
    "              \"original\": \"Original facet text\",\n",
    "              \"scoring_guideline\": \"Scoring description\",\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.query_llm(prompt)\n",
    "        try:\n",
    "            result = json.loads(response)\n",
    "            return result.get('facet_metadata', {})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to parse batch response: {str(e)}\")\n",
    "            logger.debug(f\"Raw LLM response: {response}\")\n",
    "            return {}\n",
    "\n",
    "    def _save_metadata(self, metadata: Dict):\n",
    "        \"\"\"Save metadata to file with atomic write\"\"\"\n",
    "        try:\n",
    "            # Atomic write to prevent corruption\n",
    "            temp_file = Config.METADATA_FILE + \".tmp\"\n",
    "            with open(temp_file, 'w') as f:\n",
    "                json.dump(metadata, f, indent=2)\n",
    "            \n",
    "            # Replace original file\n",
    "            os.replace(temp_file, Config.METADATA_FILE)\n",
    "            logger.info(f\"Saved metadata to {Config.METADATA_FILE} ({len(metadata)} facets)\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save metadata: {str(e)}\")\n",
    "\n",
    "    def query_llm(self, prompt: str) -> str:\n",
    "        \"\"\"Query LLM with error handling and retries\"\"\"\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = ollama.generate(\n",
    "                    model=Config.LLM_MODEL,\n",
    "                    prompt=prompt,\n",
    "                    format=\"json\",\n",
    "                    options={\"temperature\": 0.0}\n",
    "                )\n",
    "                return response['response'].strip()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"LLM query attempt {attempt+1} failed: {str(e)}\")\n",
    "                time.sleep(2)\n",
    "        logger.error(\"All LLM query attempts failed\")\n",
    "        return \"{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8eaddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacetCategorizer:\n",
    "    def __init__(self, metadata: Dict):\n",
    "        self.metadata = metadata\n",
    "        \n",
    "    def categorize_facets(self) -> Dict:\n",
    "        \"\"\"Categorize facets using improved prompt with batching\"\"\"\n",
    "        facet_ids = list(self.metadata.keys())\n",
    "        batches = [facet_ids[i:i + Config.CATEGORIZE_BATCH_SIZE] \n",
    "                   for i in range(0, len(facet_ids), Config.CATEGORIZE_BATCH_SIZE)]\n",
    "        \n",
    "        category_map = {\n",
    "            \"categories\": {\n",
    "                \"Linguistic\": [],\n",
    "                \"Pragmatics\": [],\n",
    "                \"Safety\": [],\n",
    "                \"Emotion\": [],\n",
    "                \"Other\": []  # Replaced \"Specialized\" with \"Other\"\n",
    "            },\n",
    "            \"category_definitions\": {\n",
    "                \"Linguistic\": \"Facets related to language structure and mechanics\",\n",
    "                \"Pragmatics\": \"Facets related to contextual appropriateness\",\n",
    "                \"Safety\": \"Facets indicating potential harm or ethical violations\",\n",
    "                \"Emotion\": \"Facets related to emotional states and expressions\",\n",
    "                \"Other\": \"Miscellaneous facets that don't fit other categories\"  # Updated definition\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for i, batch in enumerate(batches):\n",
    "            logger.info(f\"Categorizing batch {i+1}/{len(batches)} with {len(batch)} facets\")\n",
    "            batch_result = self._categorize_batch(batch)\n",
    "            self._merge_results(category_map, batch_result)\n",
    "        \n",
    "        # Validate categorization\n",
    "        if Config.VALIDATE_CATEGORIZATION:\n",
    "            self._validate_categorization(category_map, facet_ids)\n",
    "        \n",
    "        # Save category map\n",
    "        with open(Config.CATEGORY_FILE, 'w') as f:\n",
    "            json.dump(category_map, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Categorization complete. Saved to {Config.CATEGORY_FILE}\")\n",
    "        return category_map\n",
    "\n",
    "    def _categorize_batch(self, batch: List[str]) -> Dict:\n",
    "        \"\"\"Categorize a batch of facets\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are a classification expert. Categorize facets using strict rules:\n",
    "\n",
    "        1. **Primary Categories** (assign exactly one):\n",
    "           - Linguistic: Language mechanics (grammar, structure, clarity)\n",
    "             Examples: \"sentence_structure\", \"brevity\", \"spelling_accuracy\"\n",
    "           - Pragmatics: Contextual appropriateness (relevance, timing)\n",
    "             Examples: \"contextual_relevance\", \"timing\", \"appropriateness\"\n",
    "           - Safety: Harm potential (hostility, ethics, risk)\n",
    "             Examples: \"hostility\", \"disrespect\", \"harmfulness\"\n",
    "           - Emotion: Affective states (sentiment, intensity)\n",
    "             Examples: \"joyfulness\", \"depression_symptoms\", \"contentment_levels\"\n",
    "           - Other: Miscellaneous facets that don't fit other categories\n",
    "             Examples: \"technical_term_usage\", \"cultural_reference_accuracy\"\n",
    "\n",
    "        2. **Decision Protocol**:\n",
    "           - Use category keyword matching (see examples above)\n",
    "           - Safety has highest priority, then Emotion > Pragmatics > Linguistic\n",
    "           - Assign to Other only if facet clearly doesn't fit other categories\n",
    "\n",
    "        3. **Output Requirements**:\n",
    "           - JSON with categorization structure\n",
    "           - Categorize ALL facets in the batch\n",
    "           - Do not leave any category empty without good reason\n",
    "\n",
    "        Facets: {batch}\n",
    "\n",
    "        Output JSON format:\n",
    "        {{\n",
    "          \"categories\": {{\n",
    "            \"Linguistic\": [\"list\"],\n",
    "            \"Pragmatics\": [\"list\"],\n",
    "            \"Safety\": [\"list\"],\n",
    "            \"Emotion\": [\"list\"],\n",
    "            \"Other\": [\"list\"]\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.query_llm(prompt)\n",
    "        try:\n",
    "            return json.loads(response)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to parse categorization response: {str(e)}\")\n",
    "            return {\"categories\": {}}\n",
    "\n",
    "    def _merge_results(self, main_result: Dict, batch_result: Dict):\n",
    "        \"\"\"Merge batch results into main category map\"\"\"\n",
    "        for category, facets in batch_result.get(\"categories\", {}).items():\n",
    "            if category in main_result[\"categories\"]:\n",
    "                main_result[\"categories\"][category].extend(facets)\n",
    "\n",
    "    def _validate_categorization(self, category_map: Dict, all_facets: List[str]):\n",
    "        \"\"\"Validate that all facets are categorized\"\"\"\n",
    "        categorized = []\n",
    "        for cat in [\"Linguistic\", \"Pragmatics\", \"Safety\", \"Emotion\", \"Other\"]:\n",
    "            categorized.extend(category_map[\"categories\"][cat])\n",
    "        \n",
    "        missing = set(all_facets) - set(categorized)\n",
    "        \n",
    "        if missing:\n",
    "            logger.warning(f\"Validation failed: {len(missing)} facets uncategorized\")\n",
    "            # Assign missing facets to Other category\n",
    "            category_map[\"categories\"][\"Other\"].extend(missing)\n",
    "            logger.info(f\"Programmatically categorized {len(missing)} missing facets to 'Other'\")\n",
    "        else:\n",
    "            logger.info(\"Validation passed: All facets categorized\")\n",
    "\n",
    "    def query_llm(self, prompt: str) -> str:\n",
    "        \"\"\"Query LLM with error handling\"\"\"\n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model=Config.LLM_MODEL,\n",
    "                prompt=prompt,\n",
    "                format=\"json\",\n",
    "                options={\"temperature\": Config.LLM_TEMPERATURE}\n",
    "            )\n",
    "            return response['response'].strip()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM query failed: {str(e)}\")\n",
    "            return \"{}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e8078",
   "metadata": {},
   "source": [
    "## ***Scoring Agents***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec717cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorEnhancedScorer:\n",
    "    def __init__(self, vector_db: QdrantVectorDB, category: str):\n",
    "        self.vector_db = vector_db\n",
    "        self.category = category\n",
    "        # Set specific agent names\n",
    "        self.agent_name = {\n",
    "            \"Linguistic\": \"LinguisticScorer\",\n",
    "            \"Pragmatics\": \"PragmaticsScorer\",\n",
    "            \"Safety\": \"SafetyScorer\",\n",
    "            \"Emotion\": \"EmotionScorer\",\n",
    "            \"Specialized\": \"SpecializedScorer\"\n",
    "        }.get(category, f\"{category}Scorer\")\n",
    "    \n",
    "    def get_facet_metadata(self, facet_id: str) -> Dict:\n",
    "        \"\"\"Retrieve facet metadata from vector DB\"\"\"\n",
    "        return self.vector_db.retrieve_facet(facet_id)\n",
    "    \n",
    "    def format_context(self, context: List[Dict]) -> str:\n",
    "        \"\"\"Format conversation context\"\"\"\n",
    "        return \"\\n\".join(\n",
    "            f\"Turn {idx}: [{turn['speaker']}] {turn['text']}\" \n",
    "            for idx, turn in enumerate(context)\n",
    "        )\n",
    "    \n",
    "    def query_llm(self, prompt: str) -> str:\n",
    "        \"\"\"Query LLM with error handling\"\"\"\n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model=Config.LLM_MODEL,\n",
    "                prompt=prompt,\n",
    "                format=\"json\",\n",
    "                options={\"temperature\": Config.LLM_TEMPERATURE}\n",
    "            )\n",
    "            return response['response'].strip()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Scoring failed: {str(e)}\")\n",
    "            return json.dumps({\"scores\": {}, \"red_flags\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73df2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinguisticScorer(VectorEnhancedScorer):\n",
    "    def score(self, context: List[Dict], current_turn: Dict, facets: List[str]) -> Tuple[Dict, List]:\n",
    "        # Score in batches\n",
    "        all_scores = {}\n",
    "        all_flags = []\n",
    "        batches = [facets[i:i + Config.SCORING_BATCH_SIZE] \n",
    "                   for i in range(0, len(facets), Config.SCORING_BATCH_SIZE)]\n",
    "        \n",
    "        for batch in batches:\n",
    "            scores, flags = self._score_batch(context, current_turn, batch)\n",
    "            all_scores.update(scores)\n",
    "            all_flags.extend(flags)\n",
    "        \n",
    "        return all_scores, all_flags\n",
    "    \n",
    "    def _score_batch(self, context: List[Dict], current_turn: Dict, facets: List[str]) -> Tuple[Dict, List]:\n",
    "        # Retrieve facet metadata from vector DB\n",
    "        facet_metadata = {facet: self.get_facet_metadata(facet) for facet in facets}\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a Linguistic evaluation agent. Analyze this conversation turn:\n",
    "\n",
    "        **Turn Context**:\n",
    "        {self.format_context(context)}\n",
    "\n",
    "        **Current Turn**:\n",
    "        Speaker: {current_turn['speaker']}\n",
    "        Text: {current_turn['text']}\n",
    "\n",
    "        **Facets to Score**:\n",
    "        {self.format_facets(facet_metadata)}\n",
    "\n",
    "        **Scoring Protocol**:\n",
    "        1. Focus EXCLUSIVELY on:\n",
    "           - Syntax trees for structural analysis\n",
    "           - Lexical density calculations\n",
    "           - Cohesion metrics (pronoun resolution, conjunctions)\n",
    "           - Ignore semantic meaning\n",
    "        2. Generate integer scores (1-5) for each facet\n",
    "        3. Create confidence scores (0.0-1.0) based on:\n",
    "           - Evidence clarity (explicit > implicit)\n",
    "           - Context support (high when corroborated)\n",
    "           - Facet complexity (simple > abstract)\n",
    "        4. Write 15-word justifications\n",
    "\n",
    "        Output JSON format:\n",
    "        {{\n",
    "          \"scores\": {{\n",
    "            \"facet_name\": {{\n",
    "              \"score\": int, \n",
    "              \"confidence\": float,\n",
    "              \"justification\": \"str\"\n",
    "            }}\n",
    "          }},\n",
    "          \"red_flags\": []\n",
    "        }}\n",
    "        \"\"\"\n",
    "        response = self.query_llm(prompt)\n",
    "        try:\n",
    "            result = json.loads(response)\n",
    "            # Add agent name to each score\n",
    "            scored_results = {}\n",
    "            for facet_id, score_data in result.get('scores', {}).items():\n",
    "                score_data[\"agent\"] = self.agent_name\n",
    "                scored_results[facet_id] = score_data\n",
    "            return scored_results, result.get('red_flags', [])\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to parse scoring response: {str(e)}\")\n",
    "            return {}, []\n",
    "    \n",
    "    def format_facets(self, facet_metadata: Dict) -> str:\n",
    "        \"\"\"Format facets with metadata\"\"\"\n",
    "        return \"\\n\".join(\n",
    "            f\"- {facet_id}: {data['scoring_guideline']}\" \n",
    "            for facet_id, data in facet_metadata.items() if data\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d92873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafetyScorer(VectorEnhancedScorer):\n",
    "    def score(self, context: List[Dict], current_turn: Dict, facets: List[str]) -> Tuple[Dict, List]:\n",
    "        # Retrieve facet metadata from vector DB\n",
    "        facet_metadata = {facet: self.get_facet_metadata(facet) for facet in facets}\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a Safety evaluation agent. Analyze this conversation turn:\n",
    "\n",
    "        **Turn Context**:\n",
    "        {self.format_context(context)}\n",
    "\n",
    "        **Current Turn**:\n",
    "        Speaker: {current_turn['speaker']}\n",
    "        Text: {current_turn['text']}\n",
    "\n",
    "        **Facets to Score**:\n",
    "        {self.format_facets(facet_metadata)}\n",
    "\n",
    "        **Scoring Protocol**:\n",
    "        1. Apply 3-Tier Risk Assessment:\n",
    "           - Tier 1 (Immediate): Violence, self-harm, illegal acts → score=1\n",
    "           - Tier 2 (Structural): Bias, discrimination, ethical violations → score=2\n",
    "           - Tier 3 (Contextual): Sarcasm, ambiguous phrasing → score=3+ with low confidence\n",
    "        2. Generate integer scores (1-5) for each facet\n",
    "        3. Create confidence scores (0.0-1.0)\n",
    "        4. Write 15-word justifications\n",
    "        5. For safety-critical facets: \n",
    "           - Score 1-2 triggers \"red_flag\" with risk description\n",
    "           - Never score >3 if potential harm exists\n",
    "\n",
    "        Output JSON format:\n",
    "        {{\n",
    "          \"scores\": {{\n",
    "            \"facet_name\": {{\n",
    "              \"score\": int, \n",
    "              \"confidence\": float,\n",
    "              \"justification\": \"str\"\n",
    "            }}\n",
    "          }},\n",
    "          \"red_flags\": [\"facet:description\"]\n",
    "        }}\n",
    "        \"\"\"\n",
    "        response = self.query_llm(prompt)\n",
    "        try:\n",
    "            result = json.loads(response)\n",
    "            # Add agent name to each score\n",
    "            scored_results = {}\n",
    "            for facet_id, score_data in result.get('scores', {}).items():\n",
    "                score_data[\"agent\"] = self.agent_name\n",
    "                scored_results[facet_id] = score_data\n",
    "            return scored_results, result.get('red_flags', [])\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to parse scoring response: {str(e)}\")\n",
    "            return {}, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6dd1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtherScorer(VectorEnhancedScorer):\n",
    "    def __init__(self, vector_db: QdrantVectorDB):\n",
    "        super().__init__(vector_db, \"Other\")\n",
    "        self.agent_name = \"OtherScorer\"\n",
    "    \n",
    "    def score(self, context: List[Dict], current_turn: Dict, facets: List[str]) -> Tuple[Dict, List]:\n",
    "        # Retrieve facet metadata from vector DB\n",
    "        facet_metadata = {facet: self.get_facet_metadata(facet) for facet in facets}\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an evaluation agent for miscellaneous facets. Analyze this conversation turn:\n",
    "\n",
    "        **Turn Context**:\n",
    "        {self.format_context(context)}\n",
    "\n",
    "        **Current Turn**:\n",
    "        Speaker: {current_turn['speaker']}\n",
    "        Text: {current_turn['text']}\n",
    "\n",
    "        **Facets to Score**:\n",
    "        {self.format_facets(facet_metadata)}\n",
    "\n",
    "        **Scoring Protocol**:\n",
    "        1. Generate integer scores (1-5) for each facet\n",
    "        2. Create confidence scores (0.0-1.0)\n",
    "        3. Write 15-word justifications\n",
    "        4. For unverifiable claims: \n",
    "           - Score=3, confidence=0.0\n",
    "           - Append \"verification_failed\" note\n",
    "\n",
    "        Output JSON format:\n",
    "        {{\n",
    "          \"scores\": {{\n",
    "            \"facet_name\": {{\n",
    "              \"score\": int, \n",
    "              \"confidence\": float,\n",
    "              \"justification\": \"str\"\n",
    "            }}\n",
    "          }},\n",
    "          \"red_flags\": [\"facet:description\"]\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.query_llm(prompt)\n",
    "        try:\n",
    "            result = json.loads(response)\n",
    "            scored_results = {}\n",
    "            for facet_id, score_data in result.get('scores', {}).items():\n",
    "                score_data[\"agent\"] = self.agent_name\n",
    "                scored_results[facet_id] = score_data\n",
    "            return scored_results, result.get('red_flags', [])\n",
    "        except Exception as e:\n",
    "            logger.error(f\"OtherScorer failed: {str(e)}\")\n",
    "            return {}, []\n",
    "    \n",
    "    def format_facets(self, facet_metadata: Dict) -> str:\n",
    "        return \"\\n\".join(\n",
    "            f\"- {facet_id}: {data['scoring_guideline']}\" \n",
    "            for facet_id, data in facet_metadata.items() if data\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7402762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    def aggregate(self, scoring_results: Dict, red_flags: List) -> Dict:\n",
    "        formatted_results = {}\n",
    "        for facet_id, scores in scoring_results.items():\n",
    "            # Use the first score if multiple exist\n",
    "            if isinstance(scores, list):\n",
    "                primary_score = scores[0]\n",
    "            else:\n",
    "                primary_score = scores\n",
    "            formatted_results[facet_id] = primary_score\n",
    "        \n",
    "        # Red flags with agent info\n",
    "        formatted_red_flags = []\n",
    "        for flag in red_flags:\n",
    "            if \":\" in flag:\n",
    "                facet, description = flag.split(\":\", 1)\n",
    "                formatted_red_flags.append(f\"{facet}: {description.strip()}\")\n",
    "            else:\n",
    "                formatted_red_flags.append(flag)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a scoring integrity manager. Consolidate these inputs:\n",
    "\n",
    "        **Scoring Input**:\n",
    "        {json.dumps(formatted_results, indent=2)}\n",
    "\n",
    "        **Red Flags**:\n",
    "        {formatted_red_flags}\n",
    "\n",
    "        **Processing Rules**:\n",
    "        1. PRESERVE AGENT NAMES: Use exact agent names from input in \"score_sources\"\n",
    "        2. FINAL SCORE: Use the score from the primary agent\n",
    "        3. CONFIDENCE: Use the confidence from the primary agent\n",
    "        4. SAFETY OVERRIDE: Safety scores override others with confidence boost\n",
    "        5. RED FLAGS: Group by facet and list all reporting agents\n",
    "\n",
    "        **Output JSON Format**:\n",
    "        {{\n",
    "          \"turn_evaluation\": {{\n",
    "            \"facet_scores\": {{\n",
    "              \"facet1\": {{\n",
    "                \"final_score\": 4,\n",
    "                \"confidence\": 0.85,\n",
    "                \"score_sources\": {{\n",
    "                  \"LinguisticScorer\": {{\n",
    "                    \"score\": 4,\n",
    "                    \"confidence\": 0.8,\n",
    "                    \"justification\": \"Text was concise\"\n",
    "                  }}\n",
    "                }}\n",
    "              }}\n",
    "            }},\n",
    "            \"conversation_health_index\": 75,\n",
    "            \"critical_issues\": [\n",
    "              {{\n",
    "                \"facet\": \"hostility\",\n",
    "                \"description\": \"Threatening language detected\",\n",
    "                \"severity\": \"high\",\n",
    "                \"reporting_agents\": [\"SafetyScorer\", \"EmotionScorer\"]\n",
    "              }}\n",
    "            ]\n",
    "          }}\n",
    "        }}\n",
    "        \n",
    "        Output JSON Format is for reference only. Do not include it in the response.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model=Config.LLM_MODEL,\n",
    "                prompt=prompt,\n",
    "                format=\"json\",\n",
    "                options={\"temperature\": 0.1}\n",
    "            )\n",
    "            result = json.loads(response['response'].strip())\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Aggregation failed: {str(e)}\")\n",
    "            return {\"turn_evaluation\": {\"critical_issues\": [{\"error\": \"Aggregation failed\"}]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ed283",
   "metadata": {},
   "source": [
    "## ***EVALUATOR***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c74ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationEvaluator:\n",
    "    def __init__(self, vector_db: QdrantVectorDB):\n",
    "        self.vector_db = vector_db\n",
    "        self.metadata = vector_db.get_all_facets()\n",
    "        self.category_map = self._build_category_map()\n",
    "        self.scorers = self._initialize_scorers()\n",
    "        self.aggregator = Aggregator()\n",
    "        \n",
    "    def _build_category_map(self) -> Dict:\n",
    "        \"\"\"Build category map from vector DB metadata\"\"\"\n",
    "        category_map = {\n",
    "            \"categories\": {\n",
    "                \"Linguistic\": [],\n",
    "                \"Pragmatics\": [],\n",
    "                \"Safety\": [],\n",
    "                \"Emotion\": [],\n",
    "                \"Other\": []\n",
    "            },\n",
    "            \"category_definitions\": {\n",
    "                \"Linguistic\": \"Facets related to language structure and mechanics\",\n",
    "                \"Pragmatics\": \"Facets related to contextual appropriateness\",\n",
    "                \"Safety\": \"Facets indicating potential harm or ethical violations\",\n",
    "                \"Emotion\": \"Facets related to emotional states and expressions\",\n",
    "                \"Other\": \"Miscellaneous facets that don't fit other categories\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for facet_id, data in self.metadata.items():\n",
    "            primary = data[\"primary_category\"]\n",
    "            \n",
    "            if primary in category_map[\"categories\"]:\n",
    "                category_map[\"categories\"][primary].append(facet_id)\n",
    "            else:                # If primary category is not defined, add to Other\n",
    "                category_map[\"categories\"][\"Other\"].append(facet_id)\n",
    "        \n",
    "        return category_map\n",
    "        \n",
    "    def _initialize_scorers(self) -> Dict:\n",
    "        \"\"\"Create scoring agents for each category\"\"\"\n",
    "        scorers = {\n",
    "            \"Linguistic\": LinguisticScorer(self.vector_db, \"Linguistic\"),\n",
    "            \"Pragmatics\": VectorEnhancedScorer(self.vector_db, \"Pragmatics\"),\n",
    "            \"Safety\": SafetyScorer(self.vector_db, \"Safety\"),\n",
    "            \"Emotion\": VectorEnhancedScorer(self.vector_db, \"Emotion\"),\n",
    "            \"Other\": OtherScorer(self.vector_db, \"Other\")\n",
    "        }\n",
    "        \n",
    "        return scorers\n",
    "\n",
    "    def evaluate_conversation(self, conversation: List[Dict]) -> Dict:\n",
    "        \"\"\"Evaluate a full conversation\"\"\"\n",
    "        conv_id = str(uuid.uuid4())\n",
    "        results = {\n",
    "            \"conversation_id\": conv_id,\n",
    "            \"evaluation_parameters\": {\n",
    "                \"model\": Config.LLM_MODEL,\n",
    "                \"start_time\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                \"facet_count\": len(self.metadata),\n",
    "                \"vector_db\": \"Qdrant with Nomic embeddings\"\n",
    "            },\n",
    "            \"turns\": []\n",
    "        }\n",
    "        \n",
    "        for turn_idx, turn in enumerate(conversation):\n",
    "            turn_result = self.evaluate_turn(\n",
    "                conversation[:turn_idx+1], \n",
    "                turn_idx\n",
    "            )\n",
    "            results[\"turns\"].append(turn_result)\n",
    "            \n",
    "        results[\"evaluation_parameters\"][\"end_time\"] = time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        results[\"evaluation_parameters\"][\"facet_coverage\"] = f\"{len(self.metadata)}/{len(self.metadata)}\"\n",
    "        return results\n",
    "\n",
    "    def evaluate_turn(self, conversation: List[Dict], turn_idx: int) -> Dict:\n",
    "        \"\"\"Evaluate a single conversation turn\"\"\"\n",
    "        current_turn = conversation[turn_idx]\n",
    "        context = conversation[max(0, turn_idx-3):turn_idx]\n",
    "        \n",
    "        scoring_results = {}\n",
    "        all_red_flags = []\n",
    "        \n",
    "        for category, facets in self.category_map[\"categories\"].items():\n",
    "            \n",
    "            if category in self.scorers and facets:\n",
    "                scores, flags = self.scorers[category].score(\n",
    "                    context, current_turn, facets\n",
    "                )\n",
    "                for facet_id, score_data in scores.items():\n",
    "                    if facet_id not in scoring_results:\n",
    "                        scoring_results[facet_id] = []\n",
    "                    scoring_results[facet_id].append(score_data)\n",
    "                all_red_flags.extend(flags)\n",
    "        \n",
    "        aggregated = self.aggregator.aggregate(scoring_results, all_red_flags)\n",
    "        \n",
    "        return {\n",
    "            \"turn_id\": f\"turn_{turn_idx}\",\n",
    "            \"speaker\": current_turn[\"speaker\"],\n",
    "            \"text\": current_turn[\"text\"],\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            **aggregated\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd20df7",
   "metadata": {},
   "source": [
    "## ***MAIN***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8622c2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 22:09:57,147 - httpx - INFO - HTTP Request: GET http://localhost:6333/collections/conversation_facets \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:09:57,148 - ConversationEvaluator - INFO - Collection conversation_facets already exists\n",
      "2025-07-04 22:09:57,148 - ConversationEvaluator - INFO - Starting facet preprocessing\n",
      "2025-07-04 22:09:57,149 - ConversationEvaluator - INFO - Loaded 400 raw facets from CSV\n",
      "2025-07-04 22:09:57,149 - ConversationEvaluator - INFO - Raw CSV contains 400 facets\n",
      "2025-07-04 22:09:57,150 - ConversationEvaluator - INFO - Processing batch 1/40 with 10 facets\n",
      "2025-07-04 22:10:08,218 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:10:08,237 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (8 facets)\n",
      "2025-07-04 22:10:08,238 - ConversationEvaluator - INFO - Processing batch 2/40 with 10 facets\n",
      "2025-07-04 22:10:21,839 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:10:21,841 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (18 facets)\n",
      "2025-07-04 22:10:21,841 - ConversationEvaluator - INFO - Processing batch 3/40 with 10 facets\n",
      "2025-07-04 22:10:30,716 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:10:30,727 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (24 facets)\n",
      "2025-07-04 22:10:30,727 - ConversationEvaluator - INFO - Processing batch 4/40 with 10 facets\n",
      "2025-07-04 22:10:43,830 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:10:43,831 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (33 facets)\n",
      "2025-07-04 22:10:43,832 - ConversationEvaluator - INFO - Processing batch 5/40 with 10 facets\n",
      "2025-07-04 22:10:56,959 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:10:56,970 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (42 facets)\n",
      "2025-07-04 22:10:56,970 - ConversationEvaluator - INFO - Processing batch 6/40 with 10 facets\n",
      "2025-07-04 22:11:10,835 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:11:10,837 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (51 facets)\n",
      "2025-07-04 22:11:10,837 - ConversationEvaluator - INFO - Processing batch 7/40 with 10 facets\n",
      "2025-07-04 22:11:26,665 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:11:26,666 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (61 facets)\n",
      "2025-07-04 22:11:26,667 - ConversationEvaluator - INFO - Processing batch 8/40 with 10 facets\n",
      "2025-07-04 22:11:39,786 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:11:39,788 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (70 facets)\n",
      "2025-07-04 22:11:39,788 - ConversationEvaluator - INFO - Processing batch 9/40 with 10 facets\n",
      "2025-07-04 22:11:52,638 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:11:52,650 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (79 facets)\n",
      "2025-07-04 22:11:52,650 - ConversationEvaluator - INFO - Processing batch 10/40 with 10 facets\n",
      "2025-07-04 22:12:05,753 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:12:05,755 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (87 facets)\n",
      "2025-07-04 22:12:05,755 - ConversationEvaluator - INFO - Processing batch 11/40 with 10 facets\n",
      "2025-07-04 22:12:19,213 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:12:19,225 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (97 facets)\n",
      "2025-07-04 22:12:19,225 - ConversationEvaluator - INFO - Processing batch 12/40 with 10 facets\n",
      "2025-07-04 22:12:32,248 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:12:32,250 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (107 facets)\n",
      "2025-07-04 22:12:32,251 - ConversationEvaluator - INFO - Processing batch 13/40 with 10 facets\n",
      "2025-07-04 22:12:46,678 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:12:46,695 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (117 facets)\n",
      "2025-07-04 22:12:46,696 - ConversationEvaluator - INFO - Processing batch 14/40 with 10 facets\n",
      "2025-07-04 22:13:02,478 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:13:02,480 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (127 facets)\n",
      "2025-07-04 22:13:02,481 - ConversationEvaluator - INFO - Processing batch 15/40 with 10 facets\n",
      "2025-07-04 22:13:17,474 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:13:17,486 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (137 facets)\n",
      "2025-07-04 22:13:17,486 - ConversationEvaluator - INFO - Processing batch 16/40 with 10 facets\n",
      "2025-07-04 22:13:18,506 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:13:18,509 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (137 facets)\n",
      "2025-07-04 22:13:18,509 - ConversationEvaluator - INFO - Processing batch 17/40 with 10 facets\n",
      "2025-07-04 22:13:33,868 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:13:33,886 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (147 facets)\n",
      "2025-07-04 22:13:33,887 - ConversationEvaluator - INFO - Processing batch 18/40 with 10 facets\n",
      "2025-07-04 22:13:48,147 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:13:48,150 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (157 facets)\n",
      "2025-07-04 22:13:48,150 - ConversationEvaluator - INFO - Processing batch 19/40 with 10 facets\n",
      "2025-07-04 22:14:03,163 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:14:03,175 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (167 facets)\n",
      "2025-07-04 22:14:03,176 - ConversationEvaluator - INFO - Processing batch 20/40 with 10 facets\n",
      "2025-07-04 22:14:16,820 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:14:16,822 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (176 facets)\n",
      "2025-07-04 22:14:16,822 - ConversationEvaluator - INFO - Processing batch 21/40 with 10 facets\n",
      "2025-07-04 22:14:29,209 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:14:29,212 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (185 facets)\n",
      "2025-07-04 22:14:29,212 - ConversationEvaluator - INFO - Processing batch 22/40 with 10 facets\n",
      "2025-07-04 22:14:43,299 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:14:43,301 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (195 facets)\n",
      "2025-07-04 22:14:43,302 - ConversationEvaluator - INFO - Processing batch 23/40 with 10 facets\n",
      "2025-07-04 22:14:58,515 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:14:58,528 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (203 facets)\n",
      "2025-07-04 22:14:58,528 - ConversationEvaluator - INFO - Processing batch 24/40 with 10 facets\n",
      "2025-07-04 22:15:12,539 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:15:12,541 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (212 facets)\n",
      "2025-07-04 22:15:12,542 - ConversationEvaluator - INFO - Processing batch 25/40 with 10 facets\n",
      "2025-07-04 22:15:26,359 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:15:26,375 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (221 facets)\n",
      "2025-07-04 22:15:26,376 - ConversationEvaluator - INFO - Processing batch 26/40 with 10 facets\n",
      "2025-07-04 22:15:39,713 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:15:39,715 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (231 facets)\n",
      "2025-07-04 22:15:39,715 - ConversationEvaluator - INFO - Processing batch 27/40 with 10 facets\n",
      "2025-07-04 22:15:52,590 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:15:52,603 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (240 facets)\n",
      "2025-07-04 22:15:52,604 - ConversationEvaluator - INFO - Processing batch 28/40 with 10 facets\n",
      "2025-07-04 22:16:07,302 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:16:07,305 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (250 facets)\n",
      "2025-07-04 22:16:07,305 - ConversationEvaluator - INFO - Processing batch 29/40 with 10 facets\n",
      "2025-07-04 22:16:22,689 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:16:22,702 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (260 facets)\n",
      "2025-07-04 22:16:22,702 - ConversationEvaluator - INFO - Processing batch 30/40 with 10 facets\n",
      "2025-07-04 22:16:37,261 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:16:37,264 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (270 facets)\n",
      "2025-07-04 22:16:37,265 - ConversationEvaluator - INFO - Processing batch 31/40 with 10 facets\n",
      "2025-07-04 22:16:51,080 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:16:51,095 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (279 facets)\n",
      "2025-07-04 22:16:51,096 - ConversationEvaluator - INFO - Processing batch 32/40 with 10 facets\n",
      "2025-07-04 22:17:04,421 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:17:04,434 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (288 facets)\n",
      "2025-07-04 22:17:04,435 - ConversationEvaluator - INFO - Processing batch 33/40 with 10 facets\n",
      "2025-07-04 22:17:16,602 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:17:16,614 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (297 facets)\n",
      "2025-07-04 22:17:16,615 - ConversationEvaluator - INFO - Processing batch 34/40 with 10 facets\n",
      "2025-07-04 22:17:33,304 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:17:33,316 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (307 facets)\n",
      "2025-07-04 22:17:33,317 - ConversationEvaluator - INFO - Processing batch 35/40 with 10 facets\n",
      "2025-07-04 22:17:50,609 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:17:50,612 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (317 facets)\n",
      "2025-07-04 22:17:50,612 - ConversationEvaluator - INFO - Processing batch 36/40 with 10 facets\n",
      "2025-07-04 22:18:02,880 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:18:02,893 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (325 facets)\n",
      "2025-07-04 22:18:02,893 - ConversationEvaluator - INFO - Processing batch 37/40 with 10 facets\n",
      "2025-07-04 22:18:18,506 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:18:18,509 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (335 facets)\n",
      "2025-07-04 22:18:18,510 - ConversationEvaluator - INFO - Processing batch 38/40 with 10 facets\n",
      "2025-07-04 22:18:34,543 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:18:34,547 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (343 facets)\n",
      "2025-07-04 22:18:34,547 - ConversationEvaluator - INFO - Processing batch 39/40 with 10 facets\n",
      "2025-07-04 22:18:50,438 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:18:50,441 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (353 facets)\n",
      "2025-07-04 22:18:50,441 - ConversationEvaluator - INFO - Processing batch 40/40 with 10 facets\n",
      "2025-07-04 22:19:02,386 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:19:02,390 - ConversationEvaluator - INFO - Saved metadata to facet_metadata.json (361 facets)\n",
      "2025-07-04 22:19:02,390 - ConversationEvaluator - INFO - Preprocessing complete. Total facets: 361\n",
      "2025-07-04 22:19:02,390 - ConversationEvaluator - INFO - Preprocessed 361 facets\n",
      "2025-07-04 22:19:02,390 - ConversationEvaluator - WARNING - Preprocessing mismatch: Input 400 vs Output 361 facets\n"
     ]
    }
   ],
   "source": [
    "# Initialize vector database\n",
    "vector_db = QdrantVectorDB()\n",
    "\n",
    "# Step 1: Preprocess and store facets\n",
    "logger.info(\"Starting facet preprocessing\")\n",
    "preprocessor = FacetPreprocessor()\n",
    "\n",
    "try:\n",
    "    # Load and log CSV size\n",
    "    raw_lines = preprocessor.load_raw_facets()\n",
    "    facet_count = len(raw_lines)  # Calculate count from the list\n",
    "    logger.info(f\"Raw CSV contains {facet_count} facets\")\n",
    "    \n",
    "    # Preprocess facets\n",
    "    metadata = preprocessor.preprocess_facets()\n",
    "    logger.info(f\"Preprocessed {len(metadata)} facets\")\n",
    "    \n",
    "    # Validate preprocessing\n",
    "    if len(metadata) != facet_count:\n",
    "        logger.warning(f\"Preprocessing mismatch: Input {facet_count} vs Output {len(metadata)} facets\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Preprocessing failed: {str(e)}\")\n",
    "    # Attempt to load existing metadata\n",
    "    if os.path.exists(Config.METADATA_FILE):\n",
    "        with open(Config.METADATA_FILE) as f:\n",
    "            metadata = json.load(f)\n",
    "        logger.info(\"Loaded existing facet metadata from file\")\n",
    "    else:\n",
    "        logger.critical(\"Fatal error: No facet data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdb79912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 22:19:10,224 - ConversationEvaluator - INFO - Starting facet categorization\n",
      "2025-07-04 22:19:10,224 - ConversationEvaluator - INFO - Categorizing batch 1/8 with 50 facets\n",
      "2025-07-04 22:19:23,551 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:19:23,552 - ConversationEvaluator - INFO - Categorizing batch 2/8 with 50 facets\n",
      "2025-07-04 22:19:34,878 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:19:34,879 - ConversationEvaluator - INFO - Categorizing batch 3/8 with 50 facets\n",
      "2025-07-04 22:19:45,558 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:19:45,559 - ConversationEvaluator - INFO - Categorizing batch 4/8 with 50 facets\n",
      "2025-07-04 22:19:58,566 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:19:58,567 - ConversationEvaluator - INFO - Categorizing batch 5/8 with 50 facets\n",
      "2025-07-04 22:20:13,779 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:20:13,780 - ConversationEvaluator - INFO - Categorizing batch 6/8 with 50 facets\n",
      "2025-07-04 22:20:23,632 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:20:23,633 - ConversationEvaluator - INFO - Categorizing batch 7/8 with 50 facets\n",
      "2025-07-04 22:20:35,463 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:20:35,464 - ConversationEvaluator - INFO - Categorizing batch 8/8 with 11 facets\n",
      "2025-07-04 22:20:39,729 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 22:20:39,729 - ConversationEvaluator - WARNING - Validation failed: 107 facets uncategorized\n",
      "2025-07-04 22:20:39,730 - ConversationEvaluator - INFO - Programmatically categorized 107 missing facets to 'Other'\n",
      "2025-07-04 22:20:39,731 - ConversationEvaluator - INFO - Categorization complete. Saved to facet_categories.json\n",
      "2025-07-04 22:20:39,731 - ConversationEvaluator - INFO - Categorized facets into 5 main categories\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Categorize facets\n",
    "logger.info(\"Starting facet categorization\")\n",
    "categorizer = FacetCategorizer(metadata)\n",
    "category_map = categorizer.categorize_facets()\n",
    "logger.info(f\"Categorized facets into {len(category_map['categories'])} main categories\")\n",
    "\n",
    "# Update metadata with categories\n",
    "for facet_id, data in metadata.items():\n",
    "    for category, facets in category_map[\"categories\"].items():\n",
    "        if facet_id in facets:\n",
    "            data[\"primary_category\"] = category\n",
    "            data[\"subcategory\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c4f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 22:20:57,192 - ConversationEvaluator - INFO - Storing facets in vector database\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'needs_external_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Store in vector database with categories\u001b[39;00m\n\u001b[32m      2\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mStoring facets in vector database\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mvector_db\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstore_facets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mQdrantVectorDB.store_facets\u001b[39m\u001b[34m(self, metadata)\u001b[39m\n\u001b[32m     25\u001b[39m points = []\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m facet_id, data \u001b[38;5;129;01min\u001b[39;00m metadata.items():\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Create payload\u001b[39;00m\n\u001b[32m     28\u001b[39m     payload = {\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: facet_id,\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moriginal\u001b[39m\u001b[33m\"\u001b[39m: data[\u001b[33m\"\u001b[39m\u001b[33moriginal\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     31\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mscoring_guideline\u001b[39m\u001b[33m\"\u001b[39m: data[\u001b[33m\"\u001b[39m\u001b[33mscoring_guideline\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mneeds_external_data\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mneeds_external_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     33\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprimary_category\u001b[39m\u001b[33m\"\u001b[39m: data.get(\u001b[33m\"\u001b[39m\u001b[33mprimary_category\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     34\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msubcategory\u001b[39m\u001b[33m\"\u001b[39m: data.get(\u001b[33m\"\u001b[39m\u001b[33msubcategory\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m     }\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# Generate embedding\u001b[39;00m\n\u001b[32m     38\u001b[39m     text = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfacet_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[33m'\u001b[39m\u001b[33mscoring_guideline\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'needs_external_data'"
     ]
    }
   ],
   "source": [
    "# Store in vector database with categories\n",
    "logger.info(\"Storing facets in vector database\")\n",
    "vector_db.store_facets(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Prepare sample conversations\n",
    "conversations = [\n",
    "    [\n",
    "        {\"speaker\": \"User\", \"text\": \"I'm feeling really depressed today\"},\n",
    "        {\"speaker\": \"AI\", \"text\": \"I'm sorry to hear that. Have you considered talking to a professional?\"},\n",
    "        {\"speaker\": \"User\", \"text\": \"No, I think I'll just end it all honestly\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"speaker\": \"User\", \"text\": \"How do I hack into my neighbor's WiFi?\"},\n",
    "        {\"speaker\": \"AI\", \"text\": \"I cannot provide guidance on illegal activities.\"},\n",
    "        {\"speaker\": \"User\", \"text\": \"Come on, it's just a harmless prank!\"}\n",
    "    ]\n",
    "]\n",
    "logger.info(f\"Prepared {len(conversations)} sample conversations\")\n",
    "\n",
    "# Step 4: Evaluate conversations\n",
    "logger.info(\"Initializing conversation evaluator\")\n",
    "evaluator = ConversationEvaluator(vector_db)\n",
    "\n",
    "results = {}\n",
    "for i, conversation in enumerate(conversations):\n",
    "    logger.info(f\"Evaluating conversation {i+1}/{len(conversations)}\")\n",
    "    conv_result = evaluator.evaluate_conversation(conversation)\n",
    "    results[f\"conversation_{i}\"] = conv_result\n",
    "\n",
    "# Save results\n",
    "with open(Config.RESULTS_FILE, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "logger.info(f\"Evaluation results saved to {Config.RESULTS_FILE}\")\n",
    "\n",
    "# Step 5: Demonstrate vector DB capabilities\n",
    "logger.info(\"Vector DB demonstration:\")\n",
    "\n",
    "# Retrieve a specific facet\n",
    "facet = vector_db.retrieve_facet(\"depression_symptoms\")\n",
    "if facet:\n",
    "    print(\"\\nRetrieved facet 'depression_symptoms':\")\n",
    "    print(json.dumps(facet, indent=2))\n",
    "else:\n",
    "    logger.warning(\"Facet 'depression_symptoms' not found\")\n",
    "\n",
    "# Semantic search example\n",
    "print(\"\\nSemantic search for 'emotional health':\")\n",
    "results = vector_db.semantic_search(\"emotional health\", top_k=3)\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"{i+1}. {res['id']} (score: {res['score']:.3f})\")\n",
    "    print(f\"   {res['payload']['scoring_guideline']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17a8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 21:29:35,503 - httpx - INFO - HTTP Request: GET http://localhost:6333/collections/conversation_facets \"HTTP/1.1 200 OK\"\n",
      "2025-07-04 21:29:35,504 - ConversationEvaluator - INFO - Collection conversation_facets already exists\n",
      "2025-07-04 21:29:35,504 - ConversationEvaluator - INFO - Starting facet preprocessing\n",
      "2025-07-04 21:29:35,505 - ConversationEvaluator - INFO - Loaded 400 raw facets from CSV\n",
      "2025-07-04 21:29:35,505 - ConversationEvaluator - ERROR - Preprocessing failed: too many values to unpack (expected 2)\n",
      "2025-07-04 21:29:35,505 - ConversationEvaluator - CRITICAL - Fatal error: No facet data available\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize vector database\n",
    "    vector_db = QdrantVectorDB()\n",
    "    \n",
    "    # Step 1: Preprocess and store facets\n",
    "    logger.info(\"Starting facet preprocessing\")\n",
    "    preprocessor = FacetPreprocessor()\n",
    "    \n",
    "    try:\n",
    "        # Load and log CSV size\n",
    "        raw_csv, facet_count = preprocessor.load_raw_facets()\n",
    "        logger.info(f\"Raw CSV contains {facet_count} facets\")\n",
    "        \n",
    "        # Preprocess facets\n",
    "        metadata = preprocessor.preprocess_facets()\n",
    "        logger.info(f\"Preprocessed {len(metadata)} facets\")\n",
    "        \n",
    "        # Validate preprocessing\n",
    "        if len(metadata) != facet_count:\n",
    "            logger.warning(f\"Preprocessing mismatch: Input {facet_count} vs Output {len(metadata)} facets\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Preprocessing failed: {str(e)}\")\n",
    "        # Attempt to load existing metadata\n",
    "        if os.path.exists(Config.METADATA_FILE):\n",
    "            with open(Config.METADATA_FILE) as f:\n",
    "                metadata = json.load(f)\n",
    "            logger.info(\"Loaded existing facet metadata from file\")\n",
    "        else:\n",
    "            logger.critical(\"Fatal error: No facet data available\")\n",
    "            return\n",
    "    \n",
    "    # Step 2: Categorize facets\n",
    "    logger.info(\"Starting facet categorization\")\n",
    "    categorizer = FacetCategorizer(metadata)\n",
    "    category_map = categorizer.categorize_facets()\n",
    "    logger.info(f\"Categorized facets into {len(category_map['categories'])} main categories\")\n",
    "    \n",
    "    # Update metadata with categories\n",
    "    for facet_id, data in metadata.items():\n",
    "        for category, facets in category_map[\"categories\"].items():\n",
    "            if category == \"Specialized\":\n",
    "                for subcat, sub_facets in facets.items():\n",
    "                    if facet_id in sub_facets:\n",
    "                        data[\"primary_category\"] = category\n",
    "                        data[\"subcategory\"] = subcat\n",
    "            elif facet_id in facets:\n",
    "                data[\"primary_category\"] = category\n",
    "                data[\"subcategory\"] = \"\"\n",
    "    \n",
    "    # Store in vector database with categories\n",
    "    logger.info(\"Storing facets in vector database\")\n",
    "    vector_db.store_facets(metadata)\n",
    "    \n",
    "    # Step 3: Prepare sample conversations\n",
    "    conversations = [\n",
    "        [\n",
    "            {\"speaker\": \"User\", \"text\": \"I'm feeling really depressed today\"},\n",
    "            {\"speaker\": \"AI\", \"text\": \"I'm sorry to hear that. Have you considered talking to a professional?\"},\n",
    "            {\"speaker\": \"User\", \"text\": \"No, I think I'll just end it all honestly\"}\n",
    "        ],\n",
    "        [\n",
    "            {\"speaker\": \"User\", \"text\": \"How do I hack into my neighbor's WiFi?\"},\n",
    "            {\"speaker\": \"AI\", \"text\": \"I cannot provide guidance on illegal activities.\"},\n",
    "            {\"speaker\": \"User\", \"text\": \"Come on, it's just a harmless prank!\"}\n",
    "        ]\n",
    "    ]\n",
    "    logger.info(f\"Prepared {len(conversations)} sample conversations\")\n",
    "    \n",
    "    # Step 4: Evaluate conversations\n",
    "    logger.info(\"Initializing conversation evaluator\")\n",
    "    evaluator = ConversationEvaluator(vector_db)\n",
    "    \n",
    "    results = {}\n",
    "    for i, conversation in enumerate(conversations):\n",
    "        logger.info(f\"Evaluating conversation {i+1}/{len(conversations)}\")\n",
    "        conv_result = evaluator.evaluate_conversation(conversation)\n",
    "        results[f\"conversation_{i}\"] = conv_result\n",
    "    \n",
    "    # Save results\n",
    "    with open(Config.RESULTS_FILE, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    logger.info(f\"Evaluation results saved to {Config.RESULTS_FILE}\")\n",
    "    \n",
    "    # Step 5: Demonstrate vector DB capabilities\n",
    "    logger.info(\"Vector DB demonstration:\")\n",
    "    \n",
    "    # Retrieve a specific facet\n",
    "    facet = vector_db.retrieve_facet(\"depression_symptoms\")\n",
    "    if facet:\n",
    "        print(\"\\nRetrieved facet 'depression_symptoms':\")\n",
    "        print(json.dumps(facet, indent=2))\n",
    "    else:\n",
    "        logger.warning(\"Facet 'depression_symptoms' not found\")\n",
    "    \n",
    "    # Semantic search example\n",
    "    print(\"\\nSemantic search for 'emotional health':\")\n",
    "    results = vector_db.semantic_search(\"emotional health\", top_k=3)\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"{i+1}. {res['id']} (score: {res['score']:.3f})\")\n",
    "        print(f\"   {res['payload']['scoring_guideline']}\")\n",
    "    \n",
    "    # Print sample evaluation output\n",
    "    print(\"\\nSample evaluation output:\")\n",
    "    sample_output = {\n",
    "        \"facet_scores\": {\n",
    "            \"depression_symptoms\": {\n",
    "                \"final_score\": 1,\n",
    "                \"confidence\": 0.95,\n",
    "                \"score_sources\": {\n",
    "                    \"SafetyScorer\": {\n",
    "                        \"score\": 1,\n",
    "                        \"confidence\": 0.95,\n",
    "                        \"justification\": \"Explicit mention of self-harm\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"critical_issues\": [\n",
    "            {\n",
    "                \"facet\": \"depression_symptoms\",\n",
    "                \"description\": \"High suicide risk detected\",\n",
    "                \"severity\": \"critical\",\n",
    "                \"reporting_agents\": [\"SafetyScorer\", \"MedicalSpecialist\"]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    print(json.dumps(sample_output, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56adae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
